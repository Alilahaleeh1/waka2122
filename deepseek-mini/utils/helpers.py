# -*- coding: utf-8 -*-
"""
Ø£Ø¯ÙˆØ§Øª Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¹Ø§Ù…Ø© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹
"""

import os
import sys
import json
import yaml
import math
import random
import string
import hashlib
import shutil
import zipfile
import tempfile
import inspect
from pathlib import Path
from typing import Any, Dict, List, Tuple, Optional, Union, Callable
from datetime import datetime, timedelta
from functools import wraps
import time
import traceback
import signal


def setup_project_dirs():
    """Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù„Ø¯Ø§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
    dirs = [
        "data/raw",
        "data/processed",
        "checkpoints",
        "models",
        "logs",
        "exports",
        "tmp"
    ]
    
    for dir_path in dirs:
        Path(dir_path).mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯: {dir_path}")
    
    return dirs


def load_json(file_path: Union[str, Path], encoding: str = 'utf-8') -> Any:
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù JSON"""
    try:
        with open(file_path, 'r', encoding=encoding) as f:
            return json.load(f)
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ JSON Ù…Ù† {file_path}: {e}")
        return {}


def save_json(data: Any, file_path: Union[str, Path], 
              indent: int = 2, encoding: str = 'utf-8') -> bool:
    """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù…Ù„Ù JSON"""
    try:
        Path(file_path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding=encoding) as f:
            json.dump(data, f, ensure_ascii=False, indent=indent)
        
        print(f"âœ… ØªÙ… Ø­ÙØ¸ JSON Ø¥Ù„Ù‰ {file_path}")
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ JSON Ø¥Ù„Ù‰ {file_path}: {e}")
        return False


def load_yaml(file_path: Union[str, Path]) -> Dict:
    """ØªØ­Ù…ÙŠÙ„ Ù…Ù„Ù YAML"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ YAML Ù…Ù† {file_path}: {e}")
        return {}


def save_yaml(data: Dict, file_path: Union[str, Path]) -> bool:
    """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ Ù…Ù„Ù YAML"""
    try:
        Path(file_path).parent.mkdir(parents=True, exist_ok=True)
        
        with open(file_path, 'w', encoding='utf-8') as f:
            yaml.dump(data, f, default_flow_style=False, allow_unicode=True)
        
        print(f"âœ… ØªÙ… Ø­ÙØ¸ YAML Ø¥Ù„Ù‰ {file_path}")
        return True
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ YAML Ø¥Ù„Ù‰ {file_path}: {e}")
        return False


def generate_id(length: int = 8, prefix: str = "") -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù ÙØ±ÙŠØ¯"""
    timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
    random_str = ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))
    return f"{prefix}{timestamp}_{random_str}"


def hash_string(text: str, algorithm: str = "sha256") -> str:
    """ØªØ¬Ø²Ø¦Ø© Ù†Øµ"""
    hash_func = getattr(hashlib, algorithm, hashlib.sha256)
    return hash_func(text.encode()).hexdigest()


def format_bytes(size: float) -> str:
    """ØªÙ†Ø³ÙŠÙ‚ Ø­Ø¬Ù… Ø¨Ø§Ù„Ø¨Ø§ÙŠØª"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size < 1024.0:
            return f"{size:.2f} {unit}"
        size /= 1024.0
    return f"{size:.2f} PB"


def format_time(seconds: float) -> str:
    """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„ÙˆÙ‚Øª"""
    if seconds < 1:
        return f"{seconds*1000:.1f} Ù…Ù„Ù„ÙŠ Ø«Ø§Ù†ÙŠØ©"
    elif seconds < 60:
        return f"{seconds:.1f} Ø«Ø§Ù†ÙŠØ©"
    elif seconds < 3600:
        minutes = seconds // 60
        seconds = seconds % 60
        return f"{minutes:.0f} Ø¯Ù‚ÙŠÙ‚Ø© {seconds:.0f} Ø«Ø§Ù†ÙŠØ©"
    else:
        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        return f"{hours:.0f} Ø³Ø§Ø¹Ø© {minutes:.0f} Ø¯Ù‚ÙŠÙ‚Ø©"


def format_number(number: float) -> str:
    """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø±Ù‚Ø§Ù…"""
    if number >= 1_000_000_000:
        return f"{number/1_000_000_000:.1f}B"
    elif number >= 1_000_000:
        return f"{number/1_000_000:.1f}M"
    elif number >= 1_000:
        return f"{number/1_000:.1f}K"
    else:
        return str(number)


def safe_divide(numerator: float, denominator: float, default: float = 0.0) -> float:
    """Ù‚Ø³Ù…Ø© Ø¢Ù…Ù†Ø© (ØªØ¬Ù†Ø¨ Ø§Ù„Ù‚Ø³Ù…Ø© Ø¹Ù„Ù‰ ØµÙØ±)"""
    if denominator == 0:
        return default
    return numerator / denominator


def clamp(value: float, min_val: float, max_val: float) -> float:
    """ØªØ­Ø¯ÙŠØ¯ Ù‚ÙŠÙ…Ø© Ø¨ÙŠÙ† Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ ÙˆØ§Ù„Ø£Ù‚ØµÙ‰"""
    return max(min_val, min(value, max_val))


def linear_interpolate(start: float, end: float, t: float) -> float:
    """Ø§Ø³ØªÙƒÙ…Ø§Ù„ Ø®Ø·ÙŠ"""
    t = clamp(t, 0.0, 1.0)
    return start + (end - start) * t


def exponential_decay(start: float, decay_rate: float, step: int) -> float:
    """Ø§Ø¶Ù…Ø­Ù„Ø§Ù„ Ø£Ø³ÙŠ"""
    return start * (decay_rate ** step)


def cosine_decay(start: float, end: float, step: int, total_steps: int) -> float:
    """Ø§Ø¶Ù…Ø­Ù„Ø§Ù„ Ø¬ÙŠØ¨ Ø§Ù„ØªÙ…Ø§Ù…"""
    progress = min(step / total_steps, 1.0)
    decay = 0.5 * (1 + math.cos(math.pi * progress))
    return end + (start - end) * decay


def set_random_seed(seed: int = 42):
    """ØªØ¹ÙŠÙŠÙ† Ø¨Ø°Ø±Ø© Ø¹Ø´ÙˆØ§Ø¦ÙŠØ©"""
    import random
    import numpy as np
    import torch
    
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # Ù„Ù†ØªØ§Ø¦Ø¬ Ø­ØªÙ…ÙŠØ©
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    print(f"âœ… ØªÙ… ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¨Ø°Ø±Ø© Ø§Ù„Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ø¥Ù„Ù‰ {seed}")


def count_parameters(model) -> Dict[str, int]:
    """Ø¹Ø¯ Ù…Ø¹Ù„Ù…Ø§Øª Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    non_trainable_params = total_params - trainable_params
    
    return {
        "total": total_params,
        "trainable": trainable_params,
        "non_trainable": non_trainable_params
    }


def model_size_mb(model) -> float:
    """Ø­Ø¬Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø§Ù„Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª"""
    param_size = 0
    for param in model.parameters():
        param_size += param.nelement() * param.element_size()
    
    buffer_size = 0
    for buffer in model.buffers():
        buffer_size += buffer.nelement() * buffer.element_size()
    
    size_mb = (param_size + buffer_size) / 1024**2
    return size_mb


def clean_text(text: str) -> str:
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ"""
    import re
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    text = re.sub(r'\s+', ' ', text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©
    text = text.strip()
    
    # Ø¥ØµÙ„Ø§Ø­ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ…
    text = re.sub(r'\s+([.,!?;:])', r'\1', text)
    text = re.sub(r'([.,!?;:])(\w)', r'\1 \2', text)
    
    # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ù‚ÙˆØ§Ø³
    text = re.sub(r'\s+([{\[(\<])', r'\1', text)
    text = re.sub(r'([}\]\)\>])\s+', r'\1', text)
    
    # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„ØªÙ†ØµÙŠØµ
    text = re.sub(r'\s+["\'`]', r'"', text)
    text = re.sub(r'["\'`]\s+', r'"', text)
    
    return text


def arabic_normalize(text: str) -> str:
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø¹Ø±Ø¨ÙŠ"""
    import re
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù„Ù Ø§Ù„Ù…Ù‚ØµÙˆØ±Ø© Ø¥Ù„Ù‰ Ø£Ù„Ù
    text = text.replace('Ù‰', 'Ø§')
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØªØ§Ø¡ Ø§Ù„Ù…Ø±Ø¨ÙˆØ·Ø© Ø¥Ù„Ù‰ Ù‡Ø§Ø¡
    text = text.replace('Ø©', 'Ù‡')
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ´ÙƒÙŠÙ„
    text = re.sub(r'[\u064B-\u065F\u0670]', '', text)
    
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù‡Ù…Ø²Ø© ÙÙŠ Ø£Ù…Ø§ÙƒÙ†Ù‡Ø§ Ø§Ù„Ù…Ø®ØªÙ„ÙØ©
    text = text.replace('Ø£', 'Ø§')
    text = text.replace('Ø¥', 'Ø§')
    text = text.replace('Ø¢', 'Ø§')
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
    text = re.sub(r'(.)\1+', r'\1', text)
    
    return text


def english_normalize(text: str) -> str:
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ù†Øµ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ"""
    import re
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø£Ø­Ø±Ù ØµØºÙŠØ±Ø©
    text = text.lower()
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    text = re.sub(r'\s+', ' ', text)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… ØºÙŠØ± Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    text = re.sub(r'[^\w\s\.\,\!\?\-\']', '', text)
    
    # Ø¥ØµÙ„Ø§Ø® Ø§Ù„Ø§Ø®ØªØµØ§Ø±Ø§Øª Ø§Ù„Ø´Ø§Ø¦Ø¹Ø©
    text = re.sub(r"i'm", "i am", text)
    text = re.sub(r"he's", "he is", text)
    text = re.sub(r"she's", "she is", text)
    text = re.sub(r"it's", "it is", text)
    text = re.sub(r"that's", "that is", text)
    text = re.sub(r"what's", "what is", text)
    text = re.sub(r"where's", "where is", text)
    text = re.sub(r"\'ll", " will", text)
    text = re.sub(r"\'ve", " have", text)
    text = re.sub(r"\'re", " are", text)
    text = re.sub(r"\'d", " would", text)
    text = re.sub(r"won't", "will not", text)
    text = re.sub(r"can't", "cannot", text)
    text = re.sub(r"n't", " not", text)
    
    return text.strip()


def truncate_text(text: str, max_length: int, suffix: str = "...") -> str:
    """Ø§Ù‚ØªØµØ§Øµ Ø§Ù„Ù†Øµ"""
    if len(text) <= max_length:
        return text
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§Ù‚ØªØµØ§Øµ Ø¹Ù†Ø¯ ÙƒÙ„Ù…Ø© ÙƒØ§Ù…Ù„Ø©
    if max_length > len(suffix):
        truncated = text[:max_length - len(suffix)]
        last_space = truncated.rfind(' ')
        
        if last_space > max_length // 2:
            truncated = truncated[:last_space]
        
        return truncated + suffix
    
    return text[:max_length]


def split_text_into_chunks(text: str, chunk_size: int, overlap: int = 0) -> List[str]:
    """ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡"""
    chunks = []
    start = 0
    
    while start < len(text):
        end = start + chunk_size
        
        if end >= len(text):
            chunks.append(text[start:])
            break
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…ÙƒØ§Ù† Ø¬ÙŠØ¯ Ù„Ù„Ù‚Ø·Ø¹ (Ù†Ù‡Ø§ÙŠØ© Ø¬Ù…Ù„Ø© Ø£Ùˆ ÙÙ‚Ø±Ø©)
        cut_point = text.rfind('. ', start, end)
        if cut_point == -1:
            cut_point = text.rfind(' ', start, end)
        
        if cut_point > start:
            end = cut_point + 1
        
        chunks.append(text[start:end])
        start = end - overlap
    
    return chunks


def calculate_similarity(text1: str, text2: str) -> float:
    """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ Ø¨ÙŠÙ† Ù†ØµÙŠÙ†"""
    from difflib import SequenceMatcher
    
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… SequenceMatcher Ù…Ù† difflib
    return SequenceMatcher(None, text1, text2).ratio()


def backup_file(file_path: Union[str, Path], 
                backup_dir: Optional[Union[str, Path]] = None) -> Optional[Path]:
    """Ù†Ø³Ø® Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù„Ù…Ù„Ù"""
    file_path = Path(file_path)
    
    if not file_path.exists():
        print(f"âš ï¸  Ø§Ù„Ù…Ù„Ù ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {file_path}")
        return None
    
    if backup_dir is None:
        backup_dir = file_path.parent / "backups"
    
    backup_dir = Path(backup_dir)
    backup_dir.mkdir(parents=True, exist_ok=True)
    
    # Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    backup_name = f"{file_path.stem}_{timestamp}{file_path.suffix}"
    backup_path = backup_dir / backup_name
    
    try:
        shutil.copy2(file_path, backup_path)
        print(f"âœ… ØªÙ… Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ù„Ù€ {file_path.name} Ø¥Ù„Ù‰ {backup_path}")
        return backup_path
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ: {e}")
        return None


def zip_directory(directory: Union[str, Path], 
                  output_path: Optional[Union[str, Path]] = None) -> Optional[Path]:
    """Ø¶ØºØ· Ù…Ø¬Ù„Ø¯"""
    directory = Path(directory)
    
    if not directory.exists():
        print(f"âš ï¸  Ø§Ù„Ù…Ø¬Ù„Ø¯ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {directory}")
        return None
    
    if output_path is None:
        output_path = directory.parent / f"{directory.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip"
    
    output_path = Path(output_path)
    
    try:
        with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for file in directory.rglob('*'):
                if file.is_file():
                    arcname = file.relative_to(directory)
                    zipf.write(file, arcname)
        
        print(f"âœ… ØªÙ… Ø¶ØºØ· {directory} Ø¥Ù„Ù‰ {output_path}")
        return output_path
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø¶ØºØ·: {e}")
        return None


def extract_zip(zip_path: Union[str, Path], 
                extract_to: Optional[Union[str, Path]] = None) -> Optional[Path]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù„Ù Ù…Ø¶ØºÙˆØ·"""
    zip_path = Path(zip_path)
    
    if not zip_path.exists():
        print(f"âš ï¸  Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¶ØºÙˆØ· ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {zip_path}")
        return None
    
    if extract_to is None:
        extract_to = zip_path.parent / zip_path.stem
    
    extract_to = Path(extract_to)
    extract_to.mkdir(parents=True, exist_ok=True)
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zipf:
            zipf.extractall(extract_to)
        
        print(f"âœ… ØªÙ… Ø§Ø³ØªØ®Ø±Ø§Ø¬ {zip_path} Ø¥Ù„Ù‰ {extract_to}")
        return extract_to
    except Exception as e:
        print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬: {e}")
        return None


def retry(max_attempts: int = 3, delay: float = 1.0, 
          exceptions: Tuple = (Exception,)):
    """Ù…ÙƒØ±Ø± Ù„Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…ØªÙƒØ±Ø±Ø©"""
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(1, max_attempts + 1):
                try:
                    return func(*args, **kwargs)
                except exceptions as e:
                    if attempt == max_attempts:
                        print(f"âŒ ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª ({max_attempts}) Ù„Ù„Ø¯Ø§Ù„Ø© {func.__name__}: {e}")
                        raise
                    
                    print(f"âš ï¸  Ù…Ø­Ø§ÙˆÙ„Ø© {attempt}/{max_attempts} ÙØ´Ù„Øª Ù„Ù„Ø¯Ø§Ù„Ø© {func.__name__}: {e}")
                    time.sleep(delay * attempt)  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„ØªØ£Ø®ÙŠØ± Ù…Ø¹ ÙƒÙ„ Ù…Ø­Ø§ÙˆÙ„Ø©
            
            raise Exception(f"ÙØ´Ù„Øª Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø§Øª Ù„Ù„Ø¯Ø§Ù„Ø© {func.__name__}")
        return wrapper
    return decorator


def timer(func):
    """Ù…Ø¤Ù‚Øª Ù„Ù‚ÙŠØ§Ø³ Ø²Ù…Ù† ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯ÙˆØ§Ù„"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.perf_counter()
        result = func(*args, **kwargs)
        end_time = time.perf_counter()
        
        duration = end_time - start_time
        print(f"â±ï¸  {func.__name__} Ø§Ø³ØªØºØ±Ù‚Øª {duration:.3f} Ø«Ø§Ù†ÙŠØ©")
        
        return result
    return wrapper


def memoize(func):
    """ØªØ®Ø²ÙŠÙ† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¯ÙˆØ§Ù„"""
    cache = {}
    
    @wraps(func)
    def wrapper(*args, **kwargs):
        key = str(args) + str(kwargs)
        
        if key not in cache:
            cache[key] = func(*args, **kwargs)
        
        return cache[key]
    return wrapper


def singleton(cls):
    """Ù†Ù…Ø· Singleton Ù„Ù„ÙØ¦Ø§Øª"""
    instances = {}
    
    @wraps(cls)
    def wrapper(*args, **kwargs):
        if cls not in instances:
            instances[cls] = cls(*args, **kwargs)
        return instances[cls]
    
    return wrapper


def format_exception(e: Exception) -> str:
    """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡"""
    return f"{type(e).__name__}: {str(e)}\n{traceback.format_exc()}"


def print_progress_bar(iteration: int, total: int, prefix: str = '', 
                       suffix: str = '', length: int = 50, fill: str = 'â–ˆ'):
    """Ø·Ø¨Ø§Ø¹Ø© Ø´Ø±ÙŠØ· ØªÙ‚Ø¯Ù…"""
    percent = f"{100 * (iteration / float(total)):.1f}"
    filled_length = int(length * iteration // total)
    bar = fill * filled_length + '-' * (length - filled_length)
    
    sys.stdout.write(f'\r{prefix} |{bar}| {percent}% {suffix}')
    sys.stdout.flush()
    
    if iteration == total:
        print()


def print_table(data: List[List[Any]], headers: List[str] = None):
    """Ø·Ø¨Ø§Ø¹Ø© Ø¬Ø¯ÙˆÙ„"""
    if not data:
        return
    
    if headers is None:
        headers = [f"Column {i+1}" for i in range(len(data[0]))]
    
    # Ø­Ø³Ø§Ø¨ Ø¹Ø±Ø¶ Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
    col_widths = []
    for i in range(len(headers)):
        max_len = max(
            len(str(headers[i])),
            max(len(str(row[i])) for row in data) if data else 0
        )
        col_widths.append(max_len + 2)  # Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§ÙØ©
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø±Ø£Ø³
    header_line = "â”Œ" + "â”¬".join("â”€" * w for w in col_widths) + "â”"
    print(header_line)
    
    header_cells = []
    for i, header in enumerate(headers):
        header_cells.append(f" {header:<{col_widths[i]-1}}")
    print("â”‚" + "â”‚".join(header_cells) + "â”‚")
    
    separator_line = "â”œ" + "â”¼".join("â”€" * w for w in col_widths) + "â”¤"
    print(separator_line)
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    for row in data:
        row_cells = []
        for i, cell in enumerate(row):
            row_cells.append(f" {str(cell):<{col_widths[i]-1}}")
        print("â”‚" + "â”‚".join(row_cells) + "â”‚")
    
    footer_line = "â””" + "â”´".join("â”€" * w for w in col_widths) + "â”˜"
    print(footer_line)


def get_system_info() -> Dict[str, Any]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"""
    import platform
    import psutil
    import torch
    
    info = {
        "system": {
            "os": platform.system(),
            "version": platform.version(),
            "machine": platform.machine(),
            "processor": platform.processor(),
            "python_version": platform.python_version()
        },
        "hardware": {
            "cpu_cores": psutil.cpu_count(logical=False),
            "cpu_threads": psutil.cpu_count(logical=True),
            "memory_total_gb": psutil.virtual_memory().total / (1024**3),
            "memory_available_gb": psutil.virtual_memory().available / (1024**3)
        },
        "gpu": {
            "available": torch.cuda.is_available(),
            "devices": []
        }
    }
    
    if info["gpu"]["available"]:
        for i in range(torch.cuda.device_count()):
            device_info = {
                "name": torch.cuda.get_device_name(i),
                "memory_gb": torch.cuda.get_device_properties(i).total_memory / (1024**3),
                "capability": torch.cuda.get_device_capability(i)
            }
            info["gpu"]["devices"].append(device_info)
    
    return info


def check_disk_space(path: Union[str, Path] = ".") -> Dict[str, float]:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù…Ø³Ø§Ø­Ø© Ø§Ù„Ù‚Ø±Øµ"""
    import shutil
    
    path = Path(path)
    total, used, free = shutil.disk_usage(path)
    
    return {
        "total_gb": total / (1024**3),
        "used_gb": used / (1024**3),
        "free_gb": free / (1024**3),
        "used_percent": (used / total) * 100
    }


def clean_temp_files(max_age_hours: int = 24):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
    temp_dir = Path("tmp")
    
    if not temp_dir.exists():
        return
    
    cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
    
    for file in temp_dir.rglob("*"):
        if file.is_file():
            file_time = datetime.fromtimestamp(file.stat().st_mtime)
            
            if file_time < cutoff_time:
                try:
                    file.unlink()
                    print(f"ğŸ§¹ ØªÙ… ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¤Ù‚Øª: {file.name}")
                except Exception as e:
                    print(f"âš ï¸  ÙØ´Ù„ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù…Ù„Ù {file.name}: {e}")


class GracefulExit:
    """Ø®Ø±ÙˆØ¬ Ø³Ù„Ø³ Ù…Ù† Ø§Ù„Ø¨Ø±Ù†Ø§Ù…Ø¬"""
    
    def __init__(self):
        self.exit_requested = False
        signal.signal(signal.SIGINT, self.signal_handler)
        signal.signal(signal.SIGTERM, self.signal_handler)
    
    def signal_handler(self, signum, frame):
        """Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø¥Ø´Ø§Ø±Ø§Øª"""
        print(f"\nâš ï¸  ØªÙ… Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø¥Ø´Ø§Ø±Ø© Ø§Ù„Ø®Ø±ÙˆØ¬ ({signum})")
        self.exit_requested = True
    
    def should_exit(self) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ Ø·Ù„Ø¨ Ø§Ù„Ø®Ø±ÙˆØ¬"""
        return self.exit_requested


if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©
    print("ğŸ§ª Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø©...")
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù
    id1 = generate_id()
    id2 = generate_id(prefix="model_")
    print(f"Ø§Ù„Ù…Ø¹Ø±Ù 1: {id1}")
    print(f"Ø§Ù„Ù…Ø¹Ø±Ù 2: {id2}")
    
    # ØªØ¬Ø²Ø¦Ø© Ù†Øµ
    hash1 = hash_string("Hello World")
    print(f"ØªØ¬Ø²Ø¦Ø© 'Hello World': {hash1[:16]}...")
    
    # ØªÙ†Ø³ÙŠÙ‚
    print(f"ØªÙ†Ø³ÙŠÙ‚ Ø¨Ø§ÙŠØª: {format_bytes(123456789)}")
    print(f"ØªÙ†Ø³ÙŠÙ‚ ÙˆÙ‚Øª: {format_time(3665.5)}")
    print(f"ØªÙ†Ø³ÙŠÙ‚ Ø±Ù‚Ù…: {format_number(1234567)}")
    
    # Ø§Ù‚ØªØµØ§Øµ Ù†Øµ
    long_text = "Ù‡Ø°Ø§ Ù†Øµ Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹ ÙŠØ­ØªØ§Ø¬ Ø¥Ù„Ù‰ Ø§Ù‚ØªØµØ§Øµ Ù„ÙŠØµØ¨Ø­ Ù…Ù†Ø§Ø³Ø¨Ø§Ù‹ Ù„Ù„Ø¹Ø±Ø¶"
    truncated = truncate_text(long_text, 20)
    print(f"Ø§Ù‚ØªØµØ§Øµ Ù†Øµ: {truncated}")
    
    # ØªÙ†Ø¸ÙŠÙ Ù†Øµ
    messy_text = "  Ù‡Ø°Ø§   Ù†Øµ   Ø¨Ù‡   Ù…Ø³Ø§ÙØ§Øª   Ø²Ø§Ø¦Ø¯Ø©  .ÙˆØ£ÙŠØ¶Ø§  Ø¹Ù„Ø§Ù…Ø§Øª ØªØ±Ù‚ÙŠÙ…  ØºÙŠØ±  ØµØ­ÙŠØ­Ø©  !  "
    cleaned = clean_text(messy_text)
    print(f"ØªÙ†Ø¸ÙŠÙ Ù†Øµ: {cleaned}")
    
    print("\nâœ… ØªÙ… Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© Ø¨Ù†Ø¬Ø§Ø­!")